{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "006_text_mining_text_network_and_word_cloud.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrybrew/bigdatanalysis-bi/blob/master/006_text_mining_text_network_and_word_cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fixzFvt9HGB8",
        "colab_type": "text"
      },
      "source": [
        "# **Text Mining - Text Network & Word Cloud**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPyCX7-2NB_W",
        "colab_type": "text"
      },
      "source": [
        "## **Text Network Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXKbtyB8KIZP",
        "colab_type": "text"
      },
      "source": [
        "Though network analysis is most often used to describe relationships between people, some of the early pioneers of network analysis realized that it could also be applied to represent relationships between words. For example, one can represent a corpus of documents as a network where each node is a document, and the thickness or strength of the edges between them describes similarities between the words used in any two documents. Or, one can create a textnetwork where individual words are the nodes, and the edges between them describe the regularity with which they co-occur in documents.\n",
        "\n",
        "There are multiple advantages to a network-based approach to automated text analysis. Just as clusters of social connections can help explain a range of outcomes, understanding patterns of connections between words helps identify their meaning in a more precise manner.Second, text networks can be built out of documents of any length, whereas topic models function poorly on short texts such as social media messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQhsmBwSKxl3",
        "colab_type": "text"
      },
      "source": [
        "In this prcatice we will use NetworkX. NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. You can see the full documentation of NetworkX HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vroZ-J0c2QXR",
        "colab_type": "text"
      },
      "source": [
        "Here we construct a text network based on conversations about 'Demonetization in India'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajIRyYeAW9lq",
        "colab_type": "text"
      },
      "source": [
        "**Install & Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv2l0EPlXXLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import nltk\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from nltk import bigrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from random import seed\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb8Q4cX8IqIv",
        "colab_type": "text"
      },
      "source": [
        "**Import Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Saf4RFIout",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dianrdn/data/master/text_preprocessed_short.csv', sep = ';')\n",
        "\n",
        "# Show Data\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrOmikMd1hky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to String\n",
        "df['text']=df['text'].fillna('').apply(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Sl8MO_y5h-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select Text\n",
        "text = df['text']\n",
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBY920BBAhKW",
        "colab_type": "text"
      },
      "source": [
        "### **Preparing Adjacency Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQslFdEkzOpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize\n",
        "text_data = [word_tokenize(i) for i in text]\n",
        "print(text_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAMLUtpR13Kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Fuction to show co occurrence\n",
        "def generate_co_occurrence_matrix(corpus):\n",
        "    vocab = set(corpus)\n",
        "    vocab = list(vocab)\n",
        "    vocab_index = {word: i for i, word in enumerate(vocab)}\n",
        " \n",
        "    # Create bigrams from all words in corpus\n",
        "    bi_grams = list(bigrams(corpus))\n",
        " \n",
        "    # Frequency distribution of bigrams ((word1, word2), num_occurrences)\n",
        "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
        " \n",
        "    # Initialise co-occurrence matrix\n",
        "    # co_occurrence_matrix[current][previous]\n",
        "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n",
        " \n",
        "    # Loop through the bigrams taking the current and previous word,\n",
        "    # and the number of occurrences of the bigram.\n",
        "    for bigram in bigram_freq:\n",
        "        current = bigram[0][1]\n",
        "        previous = bigram[0][0]\n",
        "        count = bigram[1]\n",
        "        pos_current = vocab_index[current]\n",
        "        pos_previous = vocab_index[previous]\n",
        "        co_occurrence_matrix[pos_current][pos_previous] = count\n",
        "    co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n",
        " \n",
        "    # return the matrix and the index\n",
        "    return co_occurrence_matrix, vocab_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT7Vqips15iS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create one list using many lists\n",
        "data = list(itertools.chain.from_iterable(text_data))\n",
        "matrix, vocab_index = generate_co_occurrence_matrix(data)\n",
        " \n",
        " \n",
        "data_matrix = pd.DataFrame(matrix, index=vocab_index,\n",
        "                             columns=vocab_index)\n",
        "\n",
        "# Show Adjacency Matrix\n",
        "data_matrix.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IHqMGi96bvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_matrix.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9MLNkEJBFZx",
        "colab_type": "text"
      },
      "source": [
        "### **Constructing Text Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9XH2HTw07CZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Contstruct a Network\n",
        "G = nx.from_pandas_adjacency(data_matrix)\n",
        "\n",
        "# Visualize the Network\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(50,40))\n",
        "nx.draw(G, with_labels=True, \n",
        "        node_color='skyblue', node_size=600, \n",
        "        arrowstyle='->',arrowsize=20, edge_color='r',\n",
        "        font_size=7,\n",
        "        pos=nx.kamada_kawai_layout(G))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XibgWnJBoNL",
        "colab_type": "text"
      },
      "source": [
        "### **Network Metrics and Measurement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47fv2rgnKShO",
        "colab_type": "text"
      },
      "source": [
        "**Centrality Measurement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eonE6ffXKfqU",
        "colab_type": "text"
      },
      "source": [
        "In graph theory and network analysis, indicators of centrality identify the most important vertices within a graph. Applications include identifying the most influential person(s) in a social network, key infrastructure nodes in the Internet or urban networks, and super-spreaders of disease. Centrality concepts were first developed in social network analysis, and many of the terms used to measure centrality reflect their sociological origin."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG3tJEkqKVPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Degree Centrality\n",
        "degree = nx.degree_centrality(G)\n",
        "\n",
        "# Sorted from the Highest\n",
        "sorted(nx.degree(G), key=lambda x: x[1], reverse=True)[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88vr0guJOVuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Betweenness Centrality\n",
        "betweenness = nx.betweenness_centrality(G)\n",
        "\n",
        "# Sorted from the Highest\n",
        "sorted(nx.betweenness_centrality(G, normalized=True).items(), key=lambda x:x[1], reverse=True)[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRKPlKYsPGMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Closeness Centrality\n",
        "closeness = nx.closeness_centrality(G)\n",
        "\n",
        "# Sorted from the Highest\n",
        "sorted(nx.closeness_centrality(G).items(), key=lambda x:x[1], reverse=True)[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XWM0uLSPdSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eigenvector Centrality\n",
        "eigenvector = nx.eigenvector_centrality(G)\n",
        "\n",
        "# Sorted from the Highest\n",
        "sorted(nx.eigenvector_centrality(G).items(), key=lambda x:x[1], reverse=True)[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMxWj0m7De5J",
        "colab_type": "text"
      },
      "source": [
        "***Visualize Network based on Centrality Measurement***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whzLeVNKbPj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Degree Dictionary\n",
        "d = dict(degree)\n",
        "\n",
        "# Visualize the Network\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(50,40))\n",
        "nx.draw(G, with_labels=True, \n",
        "        node_color='skyblue', nodelist=d.keys(),\n",
        "        node_size=[v * 50000 for v in d.values()], \n",
        "        arrowstyle='->',arrowsize=20, edge_color='r',\n",
        "        font_size=8,\n",
        "        pos=nx.kamada_kawai_layout(G))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9j8PrQWwUA7",
        "colab_type": "text"
      },
      "source": [
        "**Network Topology Measurement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLNTtHEkRWK-",
        "colab_type": "text"
      },
      "source": [
        "The configuration, or topology, of a network is key to determining its performance. Network topology is the way a network is arranged, including the physical or logical description of how links and nodes are set up to relate to each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLuKZD791wb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show Number of Nodes\n",
        "nx.number_of_nodes(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHT180js1lHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show Number of Edges\n",
        "nx.number_of_edges(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6W83y_4xpVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show Graph Density\n",
        "nx.density(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52AuWdV1BtUZ",
        "colab_type": "text"
      },
      "source": [
        "### **Community Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qIbaO55RvCz",
        "colab_type": "text"
      },
      "source": [
        "Community detection is a fundamental problem in dividing text (modelled as nodes in a social graph) with certain word connections into densely knitted and highly related groups with each group well separated from different group members."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPq8nalnLduK",
        "colab_type": "text"
      },
      "source": [
        "**Modularity Community**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCv3Y88JeH1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Module\n",
        "from networkx.algorithms.community import greedy_modularity_communities\n",
        "\n",
        "# Modularity Community Detection\n",
        "communities_m = sorted(greedy_modularity_communities(G), key=len, reverse=True)\n",
        "communities_m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwxt7KhbHK-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Node Community Function\n",
        "def set_node_community(G, communities_m):\n",
        "      '''Add community to node attributes'''\n",
        "      for c, v_c in enumerate(communities_m):\n",
        "        for v in v_c:\n",
        "          # Add 1 to save 0 for external edges\n",
        "          G.nodes[v]['community'] = c + 1      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujM90pkvH3ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Colour Function\n",
        "def get_color(i, r_off=1, g_off=1, b_off=1):\n",
        "     '''Assign a color to a vertex.'''\n",
        "     r0, g0, b0 = 0, 0, 0\n",
        "     n = 16\n",
        "     low, high = 0.1, 0.9\n",
        "     span = high - low\n",
        "     r = low + span * (((i + r_off) * 3) % n) / (n - 1)\n",
        "     g = low + span * (((i + g_off) * 5) % n) / (n - 1)\n",
        "     b = low + span * (((i + b_off) * 7) % n) / (n - 1)\n",
        "     return (r, g, b) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9uXID-6IJfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Node Communities\n",
        "community = set_node_community(G, communities_m)\n",
        "\n",
        "# Set Node Color\n",
        "node_color = [get_color(G.nodes[v]['community']) for v in G.nodes]\n",
        "\n",
        "# Visualize the Network\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(50,40))\n",
        "nx.draw(G, with_labels=True, \n",
        "        node_color = node_color, node_size=600, \n",
        "        arrowstyle='->',arrowsize=20, edge_color='r',\n",
        "        font_size=7, map = plt.get_cmap('jet'),\n",
        "        pos=nx.kamada_kawai_layout(G))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87CZow4LNG0c",
        "colab_type": "text"
      },
      "source": [
        "## **Word Cloud**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwoMONXRViNu",
        "colab_type": "text"
      },
      "source": [
        "A word cloud is a collection, or cluster, of words depicted in different sizes. The bigger and bolder the word appears, the more often itâ€™s mentioned within a given text and the more important it is.\n",
        "\n",
        "Also known as tag clouds or text clouds, these are ideal ways to pull out the most pertinent parts of textual data, from blog posts to databases. They can also help business users compare and contrast two different pieces of text to find the wording similarities between the two."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNOv2JnJNK4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Libraries\n",
        "import wordcloud\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t19w8uySBXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Modules\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS\n",
        "\n",
        "# Build Word Cloud\n",
        "text = \" \".join(review for review in df.text)\n",
        "cloud = WordCloud(background_color='white').generate(text)\n",
        "plt.figure(figsize=(7, 7), facecolor=None)\n",
        "plt.imshow(cloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdRf95s9QUmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save File\n",
        "cloud.to_file(\"wordcloud.png\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}